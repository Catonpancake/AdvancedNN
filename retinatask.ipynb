{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import PIL\n",
    "from PIL import Image as image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "         else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2880 2136\n"
     ]
    }
   ],
   "source": [
    "data_path = './retina1_trainvalid/trainvalid'\n",
    "\n",
    "os.getcwd()\n",
    "image = PIL.Image.open(f\"{data_path}/0021.jpg\")\n",
    "width, height = image.size\n",
    "print(width, height)\n",
    "\n",
    "path, dirs, files = next(os.walk(data_path))\n",
    "file_count = len(files)\n",
    "file_count\n",
    "f = open(\"./retina1_trainvalid/labels_trainvalid.txt\", \"r\")\n",
    "y_list = list()\n",
    "f = f.readlines()\n",
    "for i in range(len(f)):\n",
    "    y_list.append(int(f[i].strip('\\n')))\n",
    "\n",
    "class SquarePad:\n",
    "    def __call__(self, image):\n",
    "        max_wh = max(image.size)\n",
    "        p_left, p_top = [(max_wh - s) // 2 for s in image.size]\n",
    "        p_right, p_bottom = [max_wh - (s+pad) for s, pad in zip(image.size, [p_left, p_top])]\n",
    "        padding = (p_left, p_top, p_right, p_bottom)\n",
    "        return F.pad(image, padding, 0, 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in ./retina1_trainvalid/trainvalid/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive\\HubRoom\\Study\\대학원\\대학원 수업\\3-1\\고급신경망응용\\Retina task\\retinatask.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     validloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(valid_data,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m                    sampler\u001b[39m=\u001b[39mvalid_sampler, batch_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trainloader, validloader\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m trainloader, validloader \u001b[39m=\u001b[39m load_split_train_vaild(data_path, \u001b[39m.2\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mprint\u001b[39m(trainloader\u001b[39m.\u001b[39mdataset[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msize())\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(np\u001b[39m.\u001b[39muint8(trainloader\u001b[39m.\u001b[39mdataset[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m255\u001b[39m))\n",
      "\u001b[1;32md:\\OneDrive\\HubRoom\\Study\\대학원\\대학원 수업\\3-1\\고급신경망응용\\Retina task\\retinatask.ipynb Cell 5\u001b[0m in \u001b[0;36mload_split_train_vaild\u001b[1;34m(datadir, valid_size)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m train_transforms \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([SquarePad(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                    transforms\u001b[39m.\u001b[39mResize(\u001b[39m224\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                                    transforms\u001b[39m.\u001b[39mToTensor(), \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                                    ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m valid_transforms \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([SquarePad(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                     transforms\u001b[39m.\u001b[39mResize(\u001b[39m224\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                                     transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                                     ])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m train_data \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mImageFolder(datadir,       \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                 transform\u001b[39m=\u001b[39;49mtrain_transforms)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m valid_data \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mImageFolder(datadir,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                 transform\u001b[39m=\u001b[39mvalid_transforms)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/HubRoom/Study/%EB%8C%80%ED%95%99%EC%9B%90/%EB%8C%80%ED%95%99%EC%9B%90%20%EC%88%98%EC%97%85/3-1/%EA%B3%A0%EA%B8%89%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%91%EC%9A%A9/Retina%20task/retinatask.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m num_train \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_data)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\datasets\\folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    302\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    303\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ):\n\u001b[1;32m--> 309\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    310\u001b[0m         root,\n\u001b[0;32m    311\u001b[0m         loader,\n\u001b[0;32m    312\u001b[0m         IMG_EXTENSIONS \u001b[39mif\u001b[39;49;00m is_valid_file \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    313\u001b[0m         transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[0;32m    314\u001b[0m         target_transform\u001b[39m=\u001b[39;49mtarget_transform,\n\u001b[0;32m    315\u001b[0m         is_valid_file\u001b[39m=\u001b[39;49mis_valid_file,\n\u001b[0;32m    316\u001b[0m     )\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\datasets\\folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    135\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    136\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    142\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform, target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 144\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_classes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[0;32m    145\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\datasets\\folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(\u001b[39mself\u001b[39m, directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[0;32m    192\u001b[0m     \u001b[39m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \n\u001b[0;32m    194\u001b[0m \u001b[39m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mreturn\u001b[39;00m find_classes(directory)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\datasets\\folder.py:42\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     40\u001b[0m classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[0;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m class_to_idx \u001b[39m=\u001b[39m {cls_name: i \u001b[39mfor\u001b[39;00m i, cls_name \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(classes)}\n\u001b[0;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in ./retina1_trainvalid/trainvalid/."
     ]
    }
   ],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "#DataLoad\n",
    "data_path = './retina1_trainvalid/trainvalid/'\n",
    "\n",
    "def load_split_train_vaild(datadir, valid_size = .2):\n",
    "    train_transforms = transforms.Compose([SquarePad(),\n",
    "                                       transforms.Resize(224),\n",
    "                                       transforms.ToTensor(), \n",
    "                                       ])\n",
    "    valid_transforms = transforms.Compose([SquarePad(),\n",
    "                                        transforms.Resize(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        ])\n",
    "    train_data = datasets.ImageFolder(datadir,       \n",
    "                    transform=train_transforms)\n",
    "    valid_data = datasets.ImageFolder(datadir,\n",
    "                    transform=valid_transforms)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=4)\n",
    "    validloader = torch.utils.data.DataLoader(valid_data,\n",
    "                   sampler=valid_sampler, batch_size=4)\n",
    "    \n",
    "\n",
    "    return trainloader, validloader\n",
    "\n",
    "trainloader, validloader = load_split_train_vaild(data_path, .2)\n",
    "print(trainloader.dataset[0][0].size())\n",
    "plt.imshow(np.uint8(trainloader.dataset[0][0].permute(1,2,0)*255))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
